#!/usr/bin/env python

import os
import logging

from collections import deque
from eden.model_base import ModelInitializerBase, main_script
from eden.sequence import Vectorizer
from GArDen.convert.sequence import FastaToSeq
from numpy.random import randint, uniform
from sklearn.linear_model import SGDClassifier


DESCRIPTION = """
GraphProt:

Explicit Decomposition with Neighborhood (EDeN) utility program for
sequence-based modeling of binding preferences of RNA-binding proteins.
"""

EPILOG = """
Author: Daniel Maticzka
Copyright: 2015
License: GPL
Maintainer: Daniel Maticzka
Email: maticzkd@informatik.uni-freiburg.de
Status: Development

Please cite:

    Daniel Maticzka, Sita J. Lange, Fabrizio Costa, Rolf Backofen
    GraphProt: modeling binding preferences of RNA-binding proteins
    Genome Biology, 2014, 15(1), R17
"""


class ModelInitializer(ModelInitializerBase):

    def _load_data(self, input_file):
        """Load fasta and transform to seq."""
        seqs = FastaToSeq(normalize=False).transform(input_file)
        return seqs

    def load_data(self, args):
        """Load and convert positive class data."""
        return self._load_data(args.input_file)

    def load_positive_data(self, args):
        """Load and convert positive class data."""
        return self._load_data(args.positive_input_file)

    def load_negative_data(self, args):
        """Load and convert negative class data."""
        return self._load_data(args.negative_input_file)

    def pre_processor_init(self, args):
        """Setup preprocessing of data prepared by load_data functions.

        Returns the function used to process the data prepared by the load_data functions and
        a set of matching parameter choices.
        """
        def pre_processor(seqs, **args):
            vp_weight = args["vp_weight"]
            context_weight = args["context_weight"]
            if "priors" in args:
                priorstable = args["priors"]
            for id, seq in seqs:
                # calculate list of viewpoint weights
                weights = map(lambda x: vp_weight if x.isupper() else context_weight, seq)
                # normalize RNA sequence
                seq = seq.upper().replace('T', 'U')
                # calculate list of RNase T1 cleavage probabilities
                if "priors" in args:
                    priors = deque()
                    # sniff kmer length from first dictionary key
                    kmer_len = len(priorstable.keys()[0])
                    # look up probabilities
                    for i in range(len(seq)):
                        try:
                            prob = priorstable[seq[i:(i + kmer_len)]]
                        except KeyError:
                            prob = None
                        priors.append(prob)
                    # compensate for the fact that the probabilities relate
                    # to the center positions of the kmers
                    priors.rotate(int(kmer_len / 2))
                    priors = list(priors)
                    # TODO multiply weights according to table given in pre_processor_parameters and weight parameter
                yield id, seq, weights

        pre_processor_parameters = {"vp_weight": [1.0],
                                    "context_weight": [0.0]}

        if (args.priors_file is not None):
            # add k-mer probabilities to parameters
            csv = open(args.priors_file, "r")
            priors = dict(map(lambda s: [s.split()[0], float(s.split()[1])], csv))
            pre_processor_parameters["priors"] = [priors]
            pre_processor_parameters["priors_weight"] = [args.priors_weight]

        return pre_processor, pre_processor_parameters

    def vectorizer_init(self, args):
        """Setup conversion of graphs to features."""
        vectorizer = Vectorizer()
        vectorizer_parameters = {
            'r': [1, 0, 2, 3, 4],
            'd': [4, 0, 1, 2, 3, 4, 5, 6],
            'nbits': [14, 16, 18]}
        return vectorizer, vectorizer_parameters

    def add_arguments(self, parser):
        """Add arguments for the main call."""
        parser.add_argument('--version', action='version', version='0.1')
        return parser

    def add_arguments_fit(self, parser):
        """Add arguments for the fit command."""
        parser.add_argument("-p", "--bound-file",
                            dest="positive_input_file",
                            help="Path to FASTA file containing sequences of bound sites.",
                            required=True)
        parser.add_argument("-n", "--unbound-file",
                            dest="negative_input_file",
                            help="Path to FASTA file containing sequences on unbound sites.",
                            required=True)
        parser.add_argument("--kmer-probs",
                            dest="priors_file",
                            default=None,
                            help="Path to tab separated file containing two columns of k-mers and associated probabilities.")
        parser.add_argument("--kmer-weight",
                            dest="priors_weight",
                            default=1.0,
                            help="Weight given to the k-mer probabilities.")
        return parser

    def add_arguments_estimate(self, parser):
        """Add arguments for the estimate command."""
        return self.add_arguments_fit(parser)

    def add_arguments_base(self, parser):
        parser.add_argument("-i", "--input-file",
                            dest="input_file",
                            help="Path to FASTA file containing input sequences.",
                            required=True)
        return parser

    def add_arguments_matrix(self, parser):
        """Add arguments used by the matrix command."""
        return parser

    def add_arguments_predict(self, parser):
        """Add arguments used by the predict command."""
        return parser

    def add_arguments_feature(self, parser):
        """Add arguments used by the feature command."""
        return parser


if __name__ == "__main__":
    model_initializer = ModelInitializer()
    main_script(model_initializer=model_initializer,
                description=DESCRIPTION,
                epilog=EPILOG,
                prog_name=os.path.basename(__file__),
                logger=logging.getLogger())
